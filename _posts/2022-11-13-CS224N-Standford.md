---
title: CS224N-Standford lecture
sidebar:
    nav: cs224n-eng
aside:
    toc: true
key: 20210713
tags: CS224N
---
First of all, This writing consists of cource Standford CS224n: Natural Language Processing with Deep Learning on Winter 2021. And it also includes 2018 CS224n because of assignment 5 related to Convolution model based on pytorch and Colab(.ipynb)

### Course Related Links
- <a href="https://web.stanford.edu/class/cs224n/">Course Main Page: Winter 2021</a><br>
- <a href="https://www.youtube.com/playlist?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ">Lecture Videos</a><br>
- <a href="https://online.stanford.edu/artificial-intelligence/free-content?category=All&course=6097">Stanford Online - CS224n</a><br>
- [Make Block diagram](https://myndbook.com/library)

### Lecture
1. Week 1 What is the basic concept and Framework in Natural Language Process?
2. Week 2 How to Calculate in Neural Network and What is the Dependency Parsing?
3. Week 3 How to struct the Dependency Parsing and the Problem solved by RNN, Bi-RNN, GRU, LTSM?
4. Week 4 Machine Translation, Sequence-to-Sequence, And Attention
5. Week 5 Self-Attention and Transformers
<br>
3. Week 3 How-to-struct-the-Dependency-Parsing-and-the-Problem-solved-by-RNN-Bi-RNN-GRU-LTSM?
4. Week 4 Machine-Translation-Sequence-to-Sequence-And-Attention

After week 5, lectures explain, <br>
- (Week 5-6) QA<br>
- (Week 6) Generation<br>
- (Week 7) Coreference Resolution<br>
- (Week 7) T5<br>
- (Week 8) Language Model<br>
- (Week 8) Ethics<br>
- (Week 9) Analysis and Explanation<br>
- (Week 9) Future<br>
<br>

But I want to learn more closer to contents related to Speech, so I completed this lecture and continue to **CS224S**

### Assignment
- [Stanford CS224n: Natural Language Processing, 2018 & 2021 solution by my hands](https://github.com/ooshyun/CS224n-Natural-Language-Processing)
- Assignment 1 Introduction to word vectors
- [Assignment 2 Derivatives and implementation of word2vec algorithm]
- [Assignment 3 Dependency Parsing]
- [Assignment 4 NMT model]
- [[2018] Assignment 5 Character-based Convolutional NMT]
- [[2021] Assignment 5 Self-Attention, Transformers, and Pretraining]

### Reference
- [https://gitlab.com/vojtamolda/stanford-cs224n-nlp-with-dl/-/tree/master/](https://gitlab.com/vojtamolda/stanford-cs224n-nlp-with-dl/-/tree/master/)
- [https://github.com/ZubinGou/CS224n-Assignment](https://github.com/ZubinGou/CS224n-Assignment)